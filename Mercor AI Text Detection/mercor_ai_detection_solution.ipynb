{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9175ca75",
   "metadata": {},
   "source": [
    "# Mercor AI Text Detection - Stacked Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adadf34",
   "metadata": {},
   "source": [
    "This notebook builds a stacked ensemble that blends stylometric features with several TF-IDF based linear models. The goal is to produce highly confident predictions (targeting perfect accuracy) for the Mercor AI Text Detection Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.base import clone\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "pd.set_option('display.max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('data')\n",
    "train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'test.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
    "\n",
    "y = train_df['is_cheating'].values\n",
    "\n",
    "print(f'Train shape: {train_df.shape}')\n",
    "print(f'Test shape: {test_df.shape}')\n",
    "print('\n",
    "Training label distribution (counts / %):')\n",
    "display(train_df['is_cheating'].value_counts().to_frame('count').assign(percent=lambda df: df['count'] / df['count'].sum() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ad2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_char_stats = train_df['answer'].str.len().describe()\n",
    "train_word_stats = train_df['answer'].str.split().apply(len).describe()\n",
    "print('Character count stats for answers:')\n",
    "display(train_char_stats.to_frame().T)\n",
    "print('Word count stats for answers:')\n",
    "display(train_word_stats.to_frame().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b61791",
   "metadata": {},
   "source": [
    "## Stylometric feature builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccae9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stylometric_features(df: pd.DataFrame) -> np.ndarray:\n",
    "    # Compute dense stylometric statistics for answer/topic text.\n",
    "    data = df.copy()\n",
    "    text = data['answer'].fillna('')\n",
    "    topic = data['topic'].fillna('')\n",
    "\n",
    "    words = text.str.split()\n",
    "    word_counts = words.apply(len)\n",
    "    unique_counts = words.apply(lambda tokens: len(set(tokens)) if tokens else 0)\n",
    "    char_counts = text.str.len()\n",
    "\n",
    "    vowel_counts = text.str.count(r'[aeiouAEIOU]')\n",
    "    digit_counts = text.str.count(r'[0-9]')\n",
    "    punctuation_counts = text.str.count(r'[.,;:!?]')\n",
    "    uppercase_counts = text.str.count(r'[A-Z]')\n",
    "    sentence_counts = text.str.count(r'[.!?]') + 1\n",
    "    newline_counts = text.str.count('\\n')\n",
    "\n",
    "    avg_word_len = char_counts / (word_counts + 1)\n",
    "    unique_ratio = unique_counts / (word_counts + 1)\n",
    "    vowel_ratio = vowel_counts / (char_counts + 1)\n",
    "    digit_ratio = digit_counts / (char_counts + 1)\n",
    "    punctuation_ratio = punctuation_counts / (char_counts + 1)\n",
    "    uppercase_ratio = uppercase_counts / (char_counts + 1)\n",
    "    words_per_sentence = word_counts / sentence_counts\n",
    "\n",
    "    topic_lengths = topic.str.len()\n",
    "    topic_word_counts = topic.str.split().apply(len)\n",
    "    topic_avg_word_len = topic_lengths / (topic_word_counts + 1)\n",
    "\n",
    "    features = np.vstack([\n",
    "        char_counts,\n",
    "        word_counts,\n",
    "        unique_counts,\n",
    "        avg_word_len,\n",
    "        unique_ratio,\n",
    "        vowel_ratio,\n",
    "        digit_ratio,\n",
    "        punctuation_ratio,\n",
    "        uppercase_ratio,\n",
    "        words_per_sentence,\n",
    "        topic_lengths,\n",
    "        topic_word_counts,\n",
    "        topic_avg_word_len,\n",
    "        newline_counts,\n",
    "    ]).astype(np.float32).T\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2b57b",
   "metadata": {},
   "source": [
    "## Base learner configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODELS = [\n",
    "    (\n",
    "        'sgd_char_3_6',\n",
    "        Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(analyzer='char', ngram_range=(3, 6), min_df=2, max_df=0.95)),\n",
    "            ('clf', SGDClassifier(loss='log_loss', penalty='elasticnet', l1_ratio=0.15, alpha=1e-4,\n",
    "                                  max_iter=4000, class_weight='balanced', n_iter_no_change=20,\n",
    "                                  random_state=RANDOM_STATE)),\n",
    "        ]),\n",
    "        'answer'\n",
    "    ),\n",
    "    (\n",
    "        'sgd_charwb_3_5',\n",
    "        Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=2, max_df=0.95)),\n",
    "            ('clf', SGDClassifier(loss='log_loss', penalty='elasticnet', l1_ratio=0.2, alpha=5e-5,\n",
    "                                  max_iter=4000, class_weight='balanced', n_iter_no_change=20,\n",
    "                                  random_state=RANDOM_STATE)),\n",
    "        ]),\n",
    "        'answer'\n",
    "    ),\n",
    "    (\n",
    "        'sgd_word_1_3',\n",
    "        Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=2, max_df=0.95, sublinear_tf=True)),\n",
    "            ('clf', SGDClassifier(loss='log_loss', penalty='elasticnet', l1_ratio=0.15, alpha=5e-4,\n",
    "                                  max_iter=3000, class_weight='balanced', n_iter_no_change=20,\n",
    "                                  random_state=RANDOM_STATE)),\n",
    "        ]),\n",
    "        'answer'\n",
    "    ),\n",
    "    (\n",
    "        'logreg_word_1_2',\n",
    "        Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=2, max_df=0.9)),\n",
    "            ('clf', LogisticRegression(max_iter=3000, C=2.0, class_weight='balanced', solver='lbfgs',\n",
    "                                      random_state=RANDOM_STATE)),\n",
    "        ]),\n",
    "        'answer'\n",
    "    ),\n",
    "    (\n",
    "        'logreg_char_4_7',\n",
    "        Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(analyzer='char', ngram_range=(4, 7), min_df=2, max_df=0.95)),\n",
    "            ('clf', LogisticRegression(max_iter=4000, C=1.5, class_weight='balanced', solver='lbfgs',\n",
    "                                      random_state=RANDOM_STATE)),\n",
    "        ]),\n",
    "        'answer'\n",
    "    ),\n",
    "    (\n",
    "        'topic_logreg',\n",
    "        Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=1, max_df=0.95)),\n",
    "            ('clf', LogisticRegression(max_iter=2000, C=1.0, random_state=RANDOM_STATE)),\n",
    "        ]),\n",
    "        'topic'\n",
    "    ),\n",
    "    (\n",
    "        'style_logreg',\n",
    "        Pipeline([\n",
    "            ('features', FunctionTransformer(lambda X: build_stylometric_features(pd.DataFrame(X, columns=['answer', 'topic'])),\n",
    "                                             validate=False)),\n",
    "            ('scaler', StandardScaler(with_mean=False)),\n",
    "            ('clf', LogisticRegression(max_iter=500, C=2.0, class_weight='balanced', random_state=RANDOM_STATE)),\n",
    "        ]),\n",
    "        'both'\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee402594",
   "metadata": {},
   "source": [
    "## Cross-validated stacking (level-1 predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "n_models = len(BASE_MODELS)\n",
    "oof_predictions = np.zeros((len(train_df), n_models), dtype=np.float32)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df, y), start=1):\n",
    "    fold_train = train_df.iloc[train_idx]\n",
    "    fold_valid = train_df.iloc[valid_idx]\n",
    "    y_train = y[train_idx]\n",
    "\n",
    "    for model_idx, (name, estimator, feature_key) in enumerate(BASE_MODELS):\n",
    "        model = clone(estimator)\n",
    "\n",
    "        if feature_key == 'answer':\n",
    "            model.fit(fold_train['answer'], y_train)\n",
    "            oof_predictions[valid_idx, model_idx] = model.predict_proba(fold_valid['answer'])[:, 1]\n",
    "        elif feature_key == 'topic':\n",
    "            model.fit(fold_train['topic'], y_train)\n",
    "            oof_predictions[valid_idx, model_idx] = model.predict_proba(fold_valid['topic'])[:, 1]\n",
    "        else:\n",
    "            model.fit(fold_train[['answer', 'topic']], y_train)\n",
    "            oof_predictions[valid_idx, model_idx] = model.predict_proba(fold_valid[['answer', 'topic']])[:, 1]\n",
    "\n",
    "    print(f'Fold {fold} finished.')\n",
    "\n",
    "base_scores = (\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            'model': [name for name, _, _ in BASE_MODELS],\n",
    "            'roc_auc': [roc_auc_score(y, oof_predictions[:, idx]) for idx in range(n_models)],\n",
    "        }\n",
    "    )\n",
    "    .sort_values('roc_auc', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(base_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4dda10",
   "metadata": {},
   "source": [
    "## Train meta-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LogisticRegression(max_iter=5000, random_state=RANDOM_STATE)\n",
    "meta_model.fit(oof_predictions, y)\n",
    "oof_meta = meta_model.predict_proba(oof_predictions)[:, 1]\n",
    "meta_auc = roc_auc_score(y, oof_meta)\n",
    "print(f'Meta-model ROC-AUC on out-of-fold predictions: {meta_auc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba6b83",
   "metadata": {},
   "source": [
    "## Fit base learners on all data & export submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_predictions = np.zeros((len(test_df), len(BASE_MODELS)), dtype=np.float32)\n",
    "\n",
    "for model_idx, (name, estimator, feature_key) in enumerate(BASE_MODELS):\n",
    "    model = clone(estimator)\n",
    "\n",
    "    if feature_key == 'answer':\n",
    "        model.fit(train_df['answer'], y)\n",
    "        full_test_predictions[:, model_idx] = model.predict_proba(test_df['answer'])[:, 1]\n",
    "    elif feature_key == 'topic':\n",
    "        model.fit(train_df['topic'], y)\n",
    "        full_test_predictions[:, model_idx] = model.predict_proba(test_df['topic'])[:, 1]\n",
    "    else:\n",
    "        model.fit(train_df[['answer', 'topic']], y)\n",
    "        full_test_predictions[:, model_idx] = model.predict_proba(test_df[['answer', 'topic']])[:, 1]\n",
    "\n",
    "final_predictions = meta_model.predict_proba(full_test_predictions)[:, 1]\n",
    "submission = pd.DataFrame({'id': test_df['id'], 'is_cheating': final_predictions})\n",
    "submission_path = Path('submission.csv')\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f'Submission file written to {submission_path.resolve()}')\n",
    "display(submission.head())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}