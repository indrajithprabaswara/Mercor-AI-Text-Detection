{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5444f8",
   "metadata": {
    "_cell_guid": "d2e1fbf2-8781-4191-9373-912eb20a219a",
    "_uuid": "24c779a6-5ba5-4a99-959f-cf27d6e5267f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-13T08:12:17.176542Z",
     "iopub.status.busy": "2025-10-13T08:12:17.176200Z",
     "iopub.status.idle": "2025-10-13T08:26:54.190137Z",
     "shell.execute_reply": "2025-10-13T08:26:54.189372Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 877.022606,
     "end_time": "2025-10-13T08:26:54.194776",
     "exception": false,
     "start_time": "2025-10-13T08:12:17.172170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有库导入完成!\n",
      "============================================================\n",
      "冠军版 - Mercor AI文本检测\n",
      "============================================================\n",
      "训练集大小: (269, 4)\n",
      "测试集大小: (264, 3)\n",
      "作弊比例: 0.546468\n",
      "\n",
      "开始训练冠军模型...\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (269, 4784)\n",
      "训练集大小: (269, 4784)\n",
      "正样本比例: 0.546468\n",
      "\n",
      "训练 Fold 1/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (242, 4757)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's binary_logloss: 0.248619\n",
      "  Fold 1 AUC: 0.977778\n",
      "\n",
      "训练 Fold 2/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (242, 4757)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[815]\tvalid_0's binary_logloss: 0.16777\n",
      "  Fold 2 AUC: 0.994444\n",
      "\n",
      "训练 Fold 3/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (242, 4758)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1111]\tvalid_0's binary_logloss: 0.187875\n",
      "  Fold 3 AUC: 0.994444\n",
      "\n",
      "训练 Fold 4/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (242, 4757)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1175]\tvalid_0's binary_logloss: 0.161467\n",
      "  Fold 4 AUC: 0.994444\n",
      "\n",
      "训练 Fold 5/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (242, 4758)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[734]\tvalid_0's binary_logloss: 0.249\n",
      "  Fold 5 AUC: 0.950000\n",
      "\n",
      "训练 Fold 6/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (242, 4757)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1133]\tvalid_0's binary_logloss: 0.0371896\n",
      "  Fold 6 AUC: 1.000000\n",
      "\n",
      "训练 Fold 7/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (242, 4757)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's binary_logloss: 0.307896\n",
      "  Fold 7 AUC: 0.950000\n",
      "\n",
      "训练 Fold 8/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (242, 4757)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1164]\tvalid_0's binary_logloss: 0.0894533\n",
      "  Fold 8 AUC: 1.000000\n",
      "\n",
      "训练 Fold 9/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (242, 4757)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1166]\tvalid_0's binary_logloss: 0.122475\n",
      "  Fold 9 AUC: 0.994505\n",
      "\n",
      "训练 Fold 10/10\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (243, 4758)\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1141]\tvalid_0's binary_logloss: 0.0539165\n",
      "  Fold 10 AUC: 1.000000\n",
      "  LGB OOF AUC: 0.984945\n",
      "  XGB OOF AUC: 0.936880\n",
      "  CAT OOF AUC: 0.981488\n",
      "  LR OOF AUC: 0.975466\n",
      "\n",
      "冠军集成 OOF AUC: 0.98282592\n",
      "\n",
      "预测测试集...\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (269, 4784)\n",
      "\n",
      "训练最终模型进行预测...\n",
      "提取冠军特征...\n",
      "创建TF-IDF特征...\n",
      "最终特征维度: (269, 4784)\n",
      "\n",
      "提交文件已保存:\n",
      "  champion_calibrated.csv - 冠军校准版本 (推荐)\n",
      "  champion_base.csv - 冠军基础版本\n",
      "\n",
      "冠军版本预测统计:\n",
      "  最小值: 0.001000\n",
      "  最大值: 0.999000\n",
      "  平均值: 0.520921\n",
      "  中位数: 0.752684\n",
      "\n",
      "前10个样本预测:\n",
      "  样本0: 0.833333\n",
      "  样本1: 0.999000\n",
      "  样本2: 0.213854\n",
      "  样本3: 0.001000\n",
      "  样本4: 0.001000\n",
      "  样本5: 0.999000\n",
      "  样本6: 0.999000\n",
      "  样本7: 0.999000\n",
      "  样本8: 0.022727\n",
      "  样本9: 0.001000\n",
      "\n",
      "各模型权重:\n",
      "  LGB: 0.2539 (OOF AUC: 0.984945)\n",
      "  XGB: 0.2415 (OOF AUC: 0.936880)\n",
      "  CAT: 0.2530 (OOF AUC: 0.981488)\n",
      "  LR: 0.2515 (OOF AUC: 0.975466)\n",
      "\n",
      "============================================================\n",
      "冠军版训练完成!\n",
      "OOF AUC: 0.98282592\n",
      "\n",
      "提交策略:\n",
      "1. 主要提交: champion_calibrated.csv (冠军校准版本)\n",
      "2. 备选: champion_base.csv (冠军基础版本)\n",
      "3. 期望目标: 超越0.978\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mercor AI Text Detection - CHAMPION VERSION\n",
    "===========================================\n",
    "Target: 0.98+ CV AUC by focusing on what actually works\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"所有库导入完成!\")\n",
    "\n",
    "class ChampionFeatureExtractor:\n",
    "    \"\"\"冠军特征提取器 - 专注于真正有效的特征\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 经过验证的最有效AI指示器\n",
    "        self.ai_connectors = [\n",
    "            'in conclusion', 'in summary', 'furthermore', 'moreover', \n",
    "            'additionally', 'however', 'therefore', 'thus', 'consequently',\n",
    "            'as a result', 'on the other hand', 'for instance', 'for example',\n",
    "            'it is important to note', 'it is worth noting', 'that being said'\n",
    "        ]\n",
    "        \n",
    "        self.formal_words = [\n",
    "            'utilize', 'facilitate', 'implement', 'methodology', 'paradigm',\n",
    "            'leverage', 'robust', 'optimal', 'enhance', 'demonstrate'\n",
    "        ]\n",
    "    \n",
    "    def extract_champion_features(self, df):\n",
    "        \"\"\"提取冠军特征 - 基于0.978版本的成功经验\"\"\"\n",
    "        features = pd.DataFrame()\n",
    "        \n",
    "        # === 基础指标 ===\n",
    "        features['text_length'] = df['answer'].str.len()\n",
    "        features['word_count'] = df['answer'].str.split().str.len()\n",
    "        features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1)\n",
    "        \n",
    "        # === 句子分析 ===\n",
    "        features['sentence_count'] = df['answer'].str.count(r'[.!?]+')\n",
    "        features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1)\n",
    "        \n",
    "        # === 标点模式 ===\n",
    "        features['comma_count'] = df['answer'].str.count(',')\n",
    "        features['period_count'] = df['answer'].str.count(r'\\.')\n",
    "        features['total_punctuation'] = features['comma_count'] + features['period_count']\n",
    "        features['punctuation_ratio'] = features['total_punctuation'] / (features['text_length'] + 1)\n",
    "        \n",
    "        # === 词汇丰富度 ===\n",
    "        features['unique_words'] = df['answer'].apply(lambda x: len(set(str(x).lower().split())))\n",
    "        features['ttr'] = features['unique_words'] / (features['word_count'] + 1)\n",
    "        \n",
    "        # === AI特定模式 ===\n",
    "        features['ai_connector_density'] = df['answer'].apply(\n",
    "            lambda x: sum(1 for phrase in self.ai_connectors if phrase in str(x).lower()) / (len(str(x).split()) + 1)\n",
    "        )\n",
    "        \n",
    "        features['formal_word_ratio'] = df['answer'].apply(\n",
    "            lambda x: sum(1 for word in self.formal_words if word in str(x).lower()) / (len(str(x).split()) + 1)\n",
    "        )\n",
    "        \n",
    "        # === 被动语态检测 ===\n",
    "        passive_indicators = ['is made', 'was made', 'is given', 'was given', 'is shown', 'was shown']\n",
    "        features['passive_voice_ratio'] = df['answer'].apply(\n",
    "            lambda x: sum(1 for phrase in passive_indicators if phrase in str(x).lower()) / (len(str(x).split()) + 1)\n",
    "        )\n",
    "        \n",
    "        # === 结构复杂度 ===\n",
    "        features['subordinate_ratio'] = df['answer'].str.count(r'\\b(that|which|who|when|where|while|although|because|if)\\b') / (features['word_count'] + 1)\n",
    "        \n",
    "        # === 一致性指标 ===\n",
    "        features['word_length_std'] = df['answer'].apply(\n",
    "            lambda x: np.std([len(w) for w in str(x).split()]) if len(str(x).split()) > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # === 主题特征 ===\n",
    "        topic_dummies = pd.get_dummies(df['topic'], prefix='topic')\n",
    "        \n",
    "        return pd.concat([features, topic_dummies], axis=1)\n",
    "\n",
    "class ChampionAIDetector:\n",
    "    \"\"\"冠军AI检测器 - 专注于最有效的模型组合\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_extractor = ChampionFeatureExtractor()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def prepare_champion_features(self, train_df, test_df):\n",
    "        \"\"\"准备冠军特征集\"\"\"\n",
    "        print(\"提取冠军特征...\")\n",
    "        train_features = self.feature_extractor.extract_champion_features(train_df)\n",
    "        test_features = self.feature_extractor.extract_champion_features(test_df)\n",
    "        \n",
    "        # 对齐列\n",
    "        test_features = test_features.reindex(columns=train_features.columns, fill_value=0)\n",
    "        \n",
    "        # TF-IDF特征（基于0.978版本的成功经验）\n",
    "        print(\"创建TF-IDF特征...\")\n",
    "        tfidf_word = TfidfVectorizer(\n",
    "            max_features=3000,\n",
    "            ngram_range=(1, 3),\n",
    "            min_df=2,\n",
    "            max_df=0.9,\n",
    "            sublinear_tf=True,\n",
    "            stop_words='english'\n",
    "        )\n",
    "        \n",
    "        tfidf_char = TfidfVectorizer(\n",
    "            max_features=1500,\n",
    "            analyzer='char_wb',\n",
    "            ngram_range=(3, 5),\n",
    "            min_df=2,\n",
    "            sublinear_tf=True\n",
    "        )\n",
    "        \n",
    "        train_tfidf_word = tfidf_word.fit_transform(train_df['answer'])\n",
    "        test_tfidf_word = tfidf_word.transform(test_df['answer'])\n",
    "        \n",
    "        train_tfidf_char = tfidf_char.fit_transform(train_df['answer'])\n",
    "        test_tfidf_char = tfidf_char.transform(test_df['answer'])\n",
    "        \n",
    "        # 组合所有特征\n",
    "        X_train = np.hstack([\n",
    "            train_tfidf_word.toarray(),\n",
    "            train_tfidf_char.toarray(),\n",
    "            train_features.values\n",
    "        ])\n",
    "        \n",
    "        X_test = np.hstack([\n",
    "            test_tfidf_word.toarray(),\n",
    "            test_tfidf_char.toarray(),\n",
    "            test_features.values\n",
    "        ])\n",
    "        \n",
    "        print(f\"最终特征维度: {X_train.shape}\")\n",
    "        return X_train, X_test\n",
    "    \n",
    "    def train_champion_ensemble(self, train_df, n_folds=10):\n",
    "        \"\"\"训练冠军集成模型\"\"\"\n",
    "        X_train, _ = self.prepare_champion_features(train_df, train_df)  # 只是为了获取特征维度\n",
    "        y_train = train_df['is_cheating'].values\n",
    "        \n",
    "        print(f\"训练集大小: {X_train.shape}\")\n",
    "        print(f\"正样本比例: {y_train.mean():.6f}\")\n",
    "        \n",
    "        # 交叉验证\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        oof_predictions = np.zeros(len(train_df))\n",
    "        \n",
    "        # 存储每个fold的测试预测\n",
    "        test_preds = {\n",
    "            'lgb': np.zeros(len(train_df)),  # 临时存储，实际我们会重新计算\n",
    "            'xgb': np.zeros(len(train_df)),\n",
    "            'cat': np.zeros(len(train_df)),\n",
    "            'lr': np.zeros(len(train_df))\n",
    "        }\n",
    "        \n",
    "        actual_test_preds = {\n",
    "            'lgb': None,\n",
    "            'xgb': None, \n",
    "            'cat': None,\n",
    "            'lr': None\n",
    "        }\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            print(f\"\\n训练 Fold {fold+1}/{n_folds}\")\n",
    "            \n",
    "            # 为每个fold重新准备特征（避免数据泄露）\n",
    "            X_train_fold, X_val_fold = self.prepare_champion_features(\n",
    "                train_df.iloc[train_idx], train_df.iloc[val_idx]\n",
    "            )\n",
    "            \n",
    "            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "            \n",
    "            # === LightGBM (优化参数) ===\n",
    "            lgb_model = lgb.LGBMClassifier(\n",
    "                n_estimators=2000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=7,\n",
    "                num_leaves=63,\n",
    "                min_child_samples=5,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.7,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=0.1,\n",
    "                random_state=42 + fold,\n",
    "                verbose=-1,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            lgb_model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=[(X_val_fold, y_val_fold)],\n",
    "                callbacks=[lgb.early_stopping(150), lgb.log_evaluation(0)]\n",
    "            )\n",
    "            \n",
    "            lgb_pred = lgb_model.predict_proba(X_val_fold)[:, 1]\n",
    "            test_preds['lgb'][val_idx] = lgb_pred\n",
    "            \n",
    "            # === XGBoost ===\n",
    "            xgb_model = xgb.XGBClassifier(\n",
    "                n_estimators=2000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=6,\n",
    "                min_child_weight=1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.7,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=0.1,\n",
    "                random_state=42 + fold,\n",
    "                eval_metric='auc',\n",
    "                tree_method='hist',\n",
    "                early_stopping_rounds=150,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            xgb_model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=[(X_val_fold, y_val_fold)],\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            xgb_pred = xgb_model.predict_proba(X_val_fold)[:, 1]\n",
    "            test_preds['xgb'][val_idx] = xgb_pred\n",
    "            \n",
    "            # === CatBoost ===\n",
    "            cat_model = CatBoostClassifier(\n",
    "                iterations=1500,\n",
    "                learning_rate=0.02,\n",
    "                depth=6,\n",
    "                l2_leaf_reg=3,\n",
    "                random_seed=42 + fold,\n",
    "                verbose=0,\n",
    "                early_stopping_rounds=150\n",
    "            )\n",
    "            \n",
    "            cat_model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=(X_val_fold, y_val_fold),\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            cat_pred = cat_model.predict_proba(X_val_fold)[:, 1]\n",
    "            test_preds['cat'][val_idx] = cat_pred\n",
    "            \n",
    "            # === Logistic Regression ===\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "            X_val_scaled = scaler.transform(X_val_fold)\n",
    "            \n",
    "            lr_model = LogisticRegression(\n",
    "                C=0.3,\n",
    "                max_iter=1000,\n",
    "                random_state=42 + fold,\n",
    "                n_jobs=-1,\n",
    "                solver='saga'\n",
    "            )\n",
    "            \n",
    "            lr_model.fit(X_train_scaled, y_train_fold)\n",
    "            lr_pred = lr_model.predict_proba(X_val_scaled)[:, 1]\n",
    "            test_preds['lr'][val_idx] = lr_pred\n",
    "            \n",
    "            # Fold集成\n",
    "            ensemble_pred = (lgb_pred + xgb_pred + cat_pred + lr_pred) / 4\n",
    "            fold_auc = roc_auc_score(y_val_fold, ensemble_pred)\n",
    "            fold_scores.append(fold_auc)\n",
    "            \n",
    "            print(f\"  Fold {fold+1} AUC: {fold_auc:.6f}\")\n",
    "        \n",
    "        # 计算各模型OOF分数\n",
    "        model_scores = {}\n",
    "        for name, preds in test_preds.items():\n",
    "            model_scores[name] = roc_auc_score(y_train, preds)\n",
    "            print(f\"  {name.upper()} OOF AUC: {model_scores[name]:.6f}\")\n",
    "        \n",
    "        # 加权集成\n",
    "        total_score = sum(model_scores.values())\n",
    "        weights = {name: score/total_score for name, score in model_scores.items()}\n",
    "        \n",
    "        oof_ensemble = sum(weights[name] * test_preds[name] for name in test_preds.keys())\n",
    "        oof_auc = roc_auc_score(y_train, oof_ensemble)\n",
    "        \n",
    "        print(f\"\\n冠军集成 OOF AUC: {oof_auc:.8f}\")\n",
    "        \n",
    "        self.model_scores = model_scores\n",
    "        self.weights = weights\n",
    "        self.is_trained = True\n",
    "        \n",
    "        return oof_auc, oof_ensemble\n",
    "    \n",
    "    def predict_champion(self, train_df, test_df):\n",
    "        \"\"\"冠军预测\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"模型尚未训练!\")\n",
    "        \n",
    "        # 准备测试特征\n",
    "        _, X_test = self.prepare_champion_features(train_df, test_df)\n",
    "        \n",
    "        # 为每个模型训练最终版本（在全量训练集上）\n",
    "        print(\"\\n训练最终模型进行预测...\")\n",
    "        \n",
    "        X_train_full, _ = self.prepare_champion_features(train_df, train_df)\n",
    "        y_train_full = train_df['is_cheating'].values\n",
    "        \n",
    "        # LightGBM最终模型\n",
    "        lgb_final = lgb.LGBMClassifier(\n",
    "            n_estimators=1500,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=7,\n",
    "            num_leaves=63,\n",
    "            min_child_samples=5,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.7,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            random_state=42,\n",
    "            verbose=-1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        lgb_final.fit(X_train_full, y_train_full)\n",
    "        lgb_test_pred = lgb_final.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # XGBoost最终模型\n",
    "        xgb_final = xgb.XGBClassifier(\n",
    "            n_estimators=1500,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=6,\n",
    "            min_child_weight=1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.7,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='auc',\n",
    "            tree_method='hist',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        xgb_final.fit(X_train_full, y_train_full)\n",
    "        xgb_test_pred = xgb_final.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # CatBoost最终模型\n",
    "        cat_final = CatBoostClassifier(\n",
    "            iterations=1200,\n",
    "            learning_rate=0.02,\n",
    "            depth=6,\n",
    "            l2_leaf_reg=3,\n",
    "            random_seed=42,\n",
    "            verbose=0\n",
    "        )\n",
    "        cat_final.fit(X_train_full, y_train_full)\n",
    "        cat_test_pred = cat_final.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Logistic Regression最终模型\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_full)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        lr_final = LogisticRegression(\n",
    "            C=0.3,\n",
    "            max_iter=1000,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            solver='saga'\n",
    "        )\n",
    "        lr_final.fit(X_train_scaled, y_train_full)\n",
    "        lr_test_pred = lr_final.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        # 使用OOF计算的权重进行集成\n",
    "        test_ensemble = (\n",
    "            lgb_test_pred * self.weights['lgb'] +\n",
    "            xgb_test_pred * self.weights['xgb'] + \n",
    "            cat_test_pred * self.weights['cat'] +\n",
    "            lr_test_pred * self.weights['lr']\n",
    "        )\n",
    "        \n",
    "        return test_ensemble, {\n",
    "            'lgb': lgb_test_pred,\n",
    "            'xgb': xgb_test_pred,\n",
    "            'cat': cat_test_pred,\n",
    "            'lr': lr_test_pred\n",
    "        }\n",
    "\n",
    "def champion_main():\n",
    "    \"\"\"冠军主函数\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"冠军版 - Mercor AI文本检测\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # 加载数据\n",
    "        train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv')\n",
    "        test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n",
    "        \n",
    "        print(f\"训练集大小: {train_df.shape}\")\n",
    "        print(f\"测试集大小: {test_df.shape}\")\n",
    "        print(f\"作弊比例: {train_df['is_cheating'].mean():.6f}\")\n",
    "        \n",
    "        # 处理缺失值\n",
    "        train_df['answer'] = train_df['answer'].fillna('')\n",
    "        test_df['answer'] = test_df['answer'].fillna('')\n",
    "        \n",
    "        # 初始化冠军检测器\n",
    "        detector = ChampionAIDetector()\n",
    "        \n",
    "        # 训练模型\n",
    "        print(\"\\n开始训练冠军模型...\")\n",
    "        oof_auc, oof_predictions = detector.train_champion_ensemble(train_df, n_folds=10)\n",
    "        \n",
    "        # 预测测试集\n",
    "        print(\"\\n预测测试集...\")\n",
    "        champion_proba, individual_preds = detector.predict_champion(train_df, test_df)\n",
    "        \n",
    "        # 应用校准\n",
    "        calibrator = IsotonicRegression(out_of_bounds='clip')\n",
    "        calibrator.fit(oof_predictions, train_df['is_cheating'].values)\n",
    "        calibrated_proba = calibrator.transform(champion_proba)\n",
    "        \n",
    "        # 确保合理范围\n",
    "        calibrated_proba = np.clip(calibrated_proba, 0.001, 0.999)\n",
    "        \n",
    "        # 创建提交文件\n",
    "        submission_champion = pd.DataFrame({\n",
    "            'id': test_df['id'],\n",
    "            'is_cheating': calibrated_proba\n",
    "        })\n",
    "        \n",
    "        submission_base = pd.DataFrame({\n",
    "            'id': test_df['id'],\n",
    "            'is_cheating': champion_proba\n",
    "        })\n",
    "        \n",
    "        # 保存文件（确保高精度）\n",
    "        submission_champion.to_csv('champion_calibrated.csv', index=False, float_format='%.10f')\n",
    "        submission_base.to_csv('champion_base.csv', index=False, float_format='%.10f')\n",
    "        \n",
    "        print(f\"\\n提交文件已保存:\")\n",
    "        print(f\"  champion_calibrated.csv - 冠军校准版本 (推荐)\")\n",
    "        print(f\"  champion_base.csv - 冠军基础版本\")\n",
    "        \n",
    "        # 详细分析\n",
    "        print(f\"\\n冠军版本预测统计:\")\n",
    "        print(f\"  最小值: {calibrated_proba.min():.6f}\")\n",
    "        print(f\"  最大值: {calibrated_proba.max():.6f}\")\n",
    "        print(f\"  平均值: {calibrated_proba.mean():.6f}\")\n",
    "        print(f\"  中位数: {np.median(calibrated_proba):.6f}\")\n",
    "        \n",
    "        print(f\"\\n前10个样本预测:\")\n",
    "        for i in range(min(10, len(test_df))):\n",
    "            print(f\"  样本{i}: {calibrated_proba[i]:.6f}\")\n",
    "        \n",
    "        # 各模型贡献分析\n",
    "        print(f\"\\n各模型权重:\")\n",
    "        for name, weight in detector.weights.items():\n",
    "            print(f\"  {name.upper()}: {weight:.4f} (OOF AUC: {detector.model_scores[name]:.6f})\")\n",
    "        \n",
    "        return submission_champion, oof_auc\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return champion_fallback()\n",
    "\n",
    "def champion_fallback():\n",
    "    \"\"\"冠军备用方案\"\"\"\n",
    "    print(\"使用冠军备用方案...\")\n",
    "    \n",
    "    train_df = pd.read_csv('/kaggle/input/mercor-ai-detection/train.csv')\n",
    "    test_df = pd.read_csv('/kaggle/input/mercor-ai-detection/test.csv')\n",
    "    \n",
    "    # 使用冠军特征提取\n",
    "    feature_extractor = ChampionFeatureExtractor()\n",
    "    train_features = feature_extractor.extract_champion_features(train_df)\n",
    "    test_features = feature_extractor.extract_champion_features(test_df)\n",
    "    \n",
    "    # 对齐列\n",
    "    test_features = test_features.reindex(columns=train_features.columns, fill_value=0)\n",
    "    \n",
    "    # 简单TF-IDF\n",
    "    tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 3), stop_words='english')\n",
    "    train_tfidf = tfidf.fit_transform(train_df['answer'])\n",
    "    test_tfidf = tfidf.transform(test_df['answer'])\n",
    "    \n",
    "    # 组合特征\n",
    "    X_train = np.hstack([train_tfidf.toarray(), train_features.values])\n",
    "    X_test = np.hstack([test_tfidf.toarray(), test_features.values])\n",
    "    y_train = train_df['is_cheating']\n",
    "    \n",
    "    # 训练LightGBM（最稳定的模型）\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        num_leaves=63,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 创建提交文件\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_df['id'],\n",
    "        'is_cheating': test_proba\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('champion_fallback.csv', index=False, float_format='%.10f')\n",
    "    \n",
    "    # 计算训练集AUC\n",
    "    train_pred = model.predict_proba(X_train)[:, 1]\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    print(f\"训练集AUC: {train_auc:.6f}\")\n",
    "    print(f\"前5个测试样本预测: {test_proba[:5]}\")\n",
    "    \n",
    "    return submission, train_auc\n",
    "\n",
    "# 运行冠军版本\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        submission, oof_auc = champion_main()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"冠军版训练完成!\")\n",
    "        print(f\"OOF AUC: {oof_auc:.8f}\")\n",
    "        print(\"\\n提交策略:\")\n",
    "        print(\"1. 主要提交: champion_calibrated.csv (冠军校准版本)\")\n",
    "        print(\"2. 备选: champion_base.csv (冠军基础版本)\")\n",
    "        print(\"3. 期望目标: 超越0.978\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"主流程失败: {e}\")\n",
    "        print(\"使用冠军备用方案...\")\n",
    "        submission, auc = champion_fallback()\n",
    "        print(f\"备用方案完成，训练AUC: {auc:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14006468,
     "sourceId": 117171,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 881.724544,
   "end_time": "2025-10-13T08:26:55.016349",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-13T08:12:13.291805",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
